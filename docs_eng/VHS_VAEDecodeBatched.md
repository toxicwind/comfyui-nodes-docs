# Documentation
- Class name: VAEDecodeBatched
- Category: Video Helper Suite ðŸŽ¥ðŸ…¥ðŸ…—ðŸ…¢/batched nodes
- Output node: False
- Repo Ref: https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite.git

The VAEDecodeBatched node is designed to decode potential samples in batches using the VAE model. It efficiently reconstructs images through batch processing of multiple samples, which is particularly useful for large data sets or for calculating limited resources.

# Input types
## Required
- samples
    - The'samplse' parameter is the key input to the VAEDecodeBatched node because it contains potential indications that the image needs to be decoded. The quality and structure of the potential sample directly influences the output image generated by the node.
    - Comfy dtype: LATENT
    - Python dtype: torch.Tensor
- vae
    - The 'vae' parameter specifies the variable coder model that will be used to decode potential samples. Model architecture and training weights are essential for generating high-quality reconstruction images.
    - Comfy dtype: VAE
    - Python dtype: torch.nn.Module
## Optional
- per_batch
    - The `per_batch' parameter determines the number of samples to be processed in each batch during the understanding code process. It is important for balancing efficiency and memory use, especially when processing large data sets.
    - Comfy dtype: INT
    - Python dtype: int

# Output types
- decoded_images
    - The 'decoded_images' output is a volume containing reconstructed images that are obtained from decoding potential samples. It represents the main result of the VAEDecodeBatched node operation.
    - Comfy dtype: IMAGE
    - Python dtype: torch.Tensor

# Usage tips
- Infra type: GPU

# Source code
```
class VAEDecodeBatched:

    @classmethod
    def INPUT_TYPES(s):
        return {'required': {'samples': ('LATENT',), 'vae': ('VAE',), 'per_batch': ('INT', {'default': 16, 'min': 1})}}
    CATEGORY = 'Video Helper Suite ðŸŽ¥ðŸ…¥ðŸ…—ðŸ…¢/batched nodes'
    RETURN_TYPES = ('IMAGE',)
    FUNCTION = 'decode'

    def decode(self, vae, samples, per_batch):
        decoded = []
        for start_idx in range(0, samples['samples'].shape[0], per_batch):
            decoded.append(vae.decode(samples['samples'][start_idx:start_idx + per_batch]))
        return (torch.cat(decoded, dim=0),)
```