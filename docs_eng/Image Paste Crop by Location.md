# Documentation
- Class name: WAS_Image_Paste_Crop_Location
- Category: WAS Suite/Image/Process
- Output node: False
- Repo Ref: https://github.com/WASasquatch/was-node-suite-comfyui

The WAS_Image_Paste_Corp_Location node is designed to operate and integrate pictures by pasting one picture to another at a given location and then cropping results. It allows fine-tunes to paste the mixing and sharpness of pictures, thus providing seamless integration in the target picture.

# Input types
## Required
- image
    - The master image, crop_image, will be pasted on it. It will serve as an operating canvas.
    - Comfy dtype: IMAGE
    - Python dtype: PIL.Image.Image
- crop_image
    - The image will be pasted to the main image. It is the main object of the pasting and cropping process.
    - Comfy dtype: IMAGE
    - Python dtype: PIL.Image.Image
## Optional
- top
    - The vertical position where the pasted picture is placed on the main image. It is essential to determine the exact location of the pasted picture.
    - Comfy dtype: INT
    - Python dtype: int
- left
    - A pasted picture places horizontally on the main image. It works with top parameters to set the paste position.
    - Comfy dtype: INT
    - Python dtype: int
- right
    - Crops the right boundary of the operation. It defines the width of the area of the crop with the left parameter.
    - Comfy dtype: INT
    - Python dtype: int
- bottom
    - Crops the lower boundary of the operation. It defines the height of the area of the crop with the top parameter.
    - Comfy dtype: INT
    - Python dtype: int
- crop_blending
    - Combining factors for pasting pictures. It controls the mixing of pasting images with the main picture, affecting the final visual appearance.
    - Comfy dtype: FLOAT
    - Python dtype: float
- crop_sharpening
    - Paste the sharpening level of the picture. Adding this value will sharpen the sharpening of the pasting image and make it more pronounced.
    - Comfy dtype: INT
    - Python dtype: int

# Output types
- result_image
    - Paste and crop the final image after the process, including a collection of the main images that are paste and cut the picture.
    - Comfy dtype: IMAGE
    - Python dtype: torch.Tensor
- result_mask
    - Mask images generated by the hybrid process can be used for further image operations or as a transparency mask.
    - Comfy dtype: IMAGE
    - Python dtype: torch.Tensor

# Usage tips
- Infra type: CPU

# Source code
```
class WAS_Image_Paste_Crop_Location:

    def __init__(self):
        pass

    @classmethod
    def INPUT_TYPES(cls):
        return {'required': {'image': ('IMAGE',), 'crop_image': ('IMAGE',), 'top': ('INT', {'default': 0, 'max': 10000000, 'min': 0, 'step': 1}), 'left': ('INT', {'default': 0, 'max': 10000000, 'min': 0, 'step': 1}), 'right': ('INT', {'default': 256, 'max': 10000000, 'min': 0, 'step': 1}), 'bottom': ('INT', {'default': 256, 'max': 10000000, 'min': 0, 'step': 1}), 'crop_blending': ('FLOAT', {'default': 0.25, 'min': 0.0, 'max': 1.0, 'step': 0.01}), 'crop_sharpening': ('INT', {'default': 0, 'min': 0, 'max': 3, 'step': 1})}}
    RETURN_TYPES = ('IMAGE', 'IMAGE')
    FUNCTION = 'image_paste_crop_location'
    CATEGORY = 'WAS Suite/Image/Process'

    def image_paste_crop_location(self, image, crop_image, top=0, left=0, right=256, bottom=256, crop_blending=0.25, crop_sharpening=0):
        (result_image, result_mask) = self.paste_image(tensor2pil(image), tensor2pil(crop_image), top, left, right, bottom, crop_blending, crop_sharpening)
        return (result_image, result_mask)

    def paste_image(self, image, crop_image, top=0, left=0, right=256, bottom=256, blend_amount=0.25, sharpen_amount=1):
        image = image.convert('RGBA')
        crop_image = crop_image.convert('RGBA')

        def inset_border(image, border_width=20, border_color=0):
            (width, height) = image.size
            bordered_image = Image.new(image.mode, (width, height), border_color)
            bordered_image.paste(image, (0, 0))
            draw = ImageDraw.Draw(bordered_image)
            draw.rectangle((0, 0, width - 1, height - 1), outline=border_color, width=border_width)
            return bordered_image
        (img_width, img_height) = image.size
        top = min(max(top, 0), img_height)
        left = min(max(left, 0), img_width)
        bottom = min(max(bottom, 0), img_height)
        right = min(max(right, 0), img_width)
        crop_size = (right - left, bottom - top)
        crop_img = crop_image.resize(crop_size)
        crop_img = crop_img.convert('RGBA')
        if sharpen_amount > 0:
            for _ in range(sharpen_amount):
                crop_img = crop_img.filter(ImageFilter.SHARPEN)
        if blend_amount > 1.0:
            blend_amount = 1.0
        elif blend_amount < 0.0:
            blend_amount = 0.0
        blend_ratio = max(crop_size) / 2 * float(blend_amount)
        blend = image.copy()
        mask = Image.new('L', image.size, 0)
        mask_block = Image.new('L', crop_size, 255)
        mask_block = inset_border(mask_block, int(blend_ratio / 2), 0)
        Image.Image.paste(mask, mask_block, (left, top))
        blend.paste(crop_img, (left, top), crop_img)
        mask = mask.filter(ImageFilter.BoxBlur(radius=blend_ratio / 4))
        mask = mask.filter(ImageFilter.GaussianBlur(radius=blend_ratio / 4))
        blend.putalpha(mask)
        image = Image.alpha_composite(image, blend)
        return (pil2tensor(image), pil2tensor(mask.convert('RGB')))
```