# Documentation
- Class name: zero123Loader
- Category: EasyUse/Loaders
- Output node: False
- Repo Ref: https://github.com/yolain/ComfyUI-Easy-Use.git

The zero123 Loader node serves as an interface for loading and managing models and images to facilitate the initialization of complex image processing and generation processes. It streamlines follow-up operations by processing the retrieval and configuration of necessary components, such as VAE and CLIP models, to ensure efficient and effective implementation.

# Input types
## Required
- ckpt_name
    - ckpt_name parameters are used to specify the checkpoints that you want to load with the parameters of the training model. This is essential for the proper running of the node and for initiating subsequent image processing and generation tasks.
    - Comfy dtype: COMBO[[['stable_zero123.ckpt']]]
    - Python dtype: str
- vae_name
    - The vae_name parameter is used to select the appropriate VAE model, which is used to generate and process the potential expressions of the image. The selection of the VAE model has a significant impact on the quality and properties of the image generated by the node.
    - Comfy dtype: COMBO[['Baked VAE'] + folder_paths.get_filename_list('vae')]
    - Python dtype: str
- init_image
    - Init_image parameters are essential because they provide the initial image data that is the starting point for image processing and task generation. The content and quality of this image directly influences the output.
    - Comfy dtype: IMAGE
    - Python dtype: PIL.Image.Image
- empty_latent_width
    - The empty_latent_width parameter defines the width of the empty potential space that will be filled to generate the content. It is a key factor in determining the resolution and size of the image.
    - Comfy dtype: INT
    - Python dtype: int
- empty_latent_height
    - The empty_latent_height parameter sets the altitude of an empty potential space, corresponding to the vertical dimension in which the image is generated. This parameter is important for controlling the width and size of the output image.
    - Comfy dtype: INT
    - Python dtype: int
- batch_size
    - 
    - Comfy dtype: INT
    - Python dtype: int
- elevation
    - The elevation parameter specifies the vertical angle of the viewing perspective of the image, influencing the view and appearance of the rendering output. It is an important factor in creating an accurate and visually attractive image.
    - Comfy dtype: FLOAT
    - Python dtype: float
- azimuth
    - The azimuth parameter determines the horizontal angle of image observation and influences the direction and layout of the image. It is essential to align the output with the visual direction desired.
    - Comfy dtype: FLOAT
    - Python dtype: float
## Optional
- prompt
    - Prompt parameters provide text guidance for the image generation process and help shape the content and style of the image. This is an optional but useful tool to guide node output in the direction of creation.
    - Comfy dtype: PROMPT
    - Python dtype: str
- my_unique_id
    - My_unique_id parameters are the only example of tracking and managing node operations to ensure that each execution is identifiable and unique. This helps to debug and maintain the integrity of the process.
    - Comfy dtype: UNIQUE_ID
    - Python dtype: str

# Output types
- pipe
    - Pipe output is an integrated structure that covers all components and settings required for image processing and generation processes. It serves as the backbone for follow-up operations and ensures smooth and coordinated workflows.
    - Comfy dtype: PIPE_LINE
    - Python dtype: dict
- model
    - Model output provides a model that is loaded and configured for use in image processing tasks. It is a key component that directly affects the quality and accuracy of image generation.
    - Comfy dtype: MODEL
    - Python dtype: comfy.model_management.ModelPatcher
- vae
    - The vae output contains the VAE model that has been initialized and is ready to be used to generate and process potential image expressions. It plays a central role in image creation, enabling nodes to produce high-quality visual effects.
    - Comfy dtype: VAE
    - Python dtype: comfy.sd.VAE

# Usage tips
- Infra type: CPU

# Source code
```
class zero123Loader:

    @classmethod
    def INPUT_TYPES(cls):

        def get_file_list(filenames):
            return [file for file in filenames if file != 'put_models_here.txt' and 'zero123' in file.lower()]
        return {'required': {'ckpt_name': (list(['stable_zero123.ckpt']),), 'vae_name': (['Baked VAE'] + folder_paths.get_filename_list('vae'),), 'init_image': ('IMAGE',), 'empty_latent_width': ('INT', {'default': 256, 'min': 16, 'max': MAX_RESOLUTION, 'step': 8}), 'empty_latent_height': ('INT', {'default': 256, 'min': 16, 'max': MAX_RESOLUTION, 'step': 8}), 'batch_size': ('INT', {'default': 1, 'min': 1, 'max': 64}), 'elevation': ('FLOAT', {'default': 0.0, 'min': -180.0, 'max': 180.0}), 'azimuth': ('FLOAT', {'default': 0.0, 'min': -180.0, 'max': 180.0})}, 'hidden': {'prompt': 'PROMPT', 'my_unique_id': 'UNIQUE_ID'}}
    RETURN_TYPES = ('PIPE_LINE', 'MODEL', 'VAE')
    RETURN_NAMES = ('pipe', 'model', 'vae')
    FUNCTION = 'adv_pipeloader'
    CATEGORY = 'EasyUse/Loaders'

    def adv_pipeloader(self, ckpt_name, vae_name, init_image, empty_latent_width, empty_latent_height, batch_size, elevation, azimuth, prompt=None, my_unique_id=None):
        model: ModelPatcher | None = None
        vae: VAE | None = None
        clip: CLIP | None = None
        clip_vision = None
        easyCache.update_loaded_objects(prompt)
        (model, clip, vae, clip_vision) = easyCache.load_checkpoint(ckpt_name, 'Default', True)
        output = clip_vision.encode_image(init_image)
        pooled = output.image_embeds.unsqueeze(0)
        pixels = comfy.utils.common_upscale(init_image.movedim(-1, 1), empty_latent_width, empty_latent_height, 'bilinear', 'center').movedim(1, -1)
        encode_pixels = pixels[:, :, :, :3]
        t = vae.encode(encode_pixels)
        cam_embeds = camera_embeddings(elevation, azimuth)
        cond = torch.cat([pooled, cam_embeds.repeat((pooled.shape[0], 1, 1))], dim=-1)
        positive = [[cond, {'concat_latent_image': t}]]
        negative = [[torch.zeros_like(pooled), {'concat_latent_image': torch.zeros_like(t)}]]
        latent = torch.zeros([batch_size, 4, empty_latent_height // 8, empty_latent_width // 8])
        samples = {'samples': latent}
        image = easySampler.pil2tensor(Image.new('RGB', (1, 1), (0, 0, 0)))
        pipe = {'model': model, 'positive': positive, 'negative': negative, 'vae': vae, 'clip': clip, 'samples': samples, 'images': image, 'seed': 0, 'loader_settings': {'ckpt_name': ckpt_name, 'vae_name': vae_name, 'positive': positive, 'positive_l': None, 'positive_g': None, 'positive_balance': None, 'negative': negative, 'negative_l': None, 'negative_g': None, 'negative_balance': None, 'empty_latent_width': empty_latent_width, 'empty_latent_height': empty_latent_height, 'batch_size': batch_size, 'seed': 0, 'empty_samples': samples}}
        return (pipe, model, vae)
```