# Documentation
- Class name: MikeySampler
- Category: Mikey/Sampling
- Output node: False
- Repo Ref: https://github.com/bash-j/mikey_nodes

The MikeySampler node is designed to generate high-quality samples from the given base and fine-tuning models, while using VAE for potential space operations. It performs complex sampling techniques and optimizes output by combining condition input. The node also expands the image generated according to the method and strength specified to ensure that the final output meets the required resolution and quality standards.

# Input types
## Required
- seed
    - Seed parameters are essential for the repeatability of the sampling process, ensuring that samples generated in different operations are consistent. They play an important role in random control of sampling algorithms.
    - Comfy dtype: INT
    - Python dtype: int
- base_model
    - The basic model is the underlying neural network used for the initial sampling of potential space. It is a key component that determines the quality and diversity of the samples generated.
    - Comfy dtype: MODEL
    - Python dtype: torch.nn.Module
- refiner_model
    - The fine-tuning model is used to further improve the quality of samples generated by the underlying model. It refines the potential spatial expression to achieve a higher level of certainty in the final output.
    - Comfy dtype: MODEL
    - Python dtype: torch.nn.Module
- samples
    - The sample parameter indicates the number of potential vectors to be sampled from the base model. It directly affects the diversity of the output generated.
    - Comfy dtype: LATENT
    - Python dtype: torch.Tensor
## Optional
- upscale_by
    - Upscale_by parameters determine the zoom factor for generating the image. It is an important factor in controlling the final output resolution.
    - Comfy dtype: FLOAT
    - Python dtype: float
- hires_strength
    - The heres_strength parameter adjusts the intensity of the high-resolution magnification process. It affects the clarity and detail level of the magnification image.
    - Comfy dtype: FLOAT
    - Python dtype: float

# Output types
- latent
    - The latent parameter indicates the potential vector of the code obtained during the sampling process. It is important because it is an intermediate expression between the model and the eventual magnification of the image.
    - Comfy dtype: LATENT
    - Python dtype: torch.Tensor

# Usage tips
- Infra type: GPU

# Source code
```
class MikeySampler:

    @classmethod
    def INPUT_TYPES(s):
        return {'required': {'base_model': ('MODEL',), 'refiner_model': ('MODEL',), 'samples': ('LATENT',), 'vae': ('VAE',), 'positive_cond_base': ('CONDITIONING',), 'negative_cond_base': ('CONDITIONING',), 'positive_cond_refiner': ('CONDITIONING',), 'negative_cond_refiner': ('CONDITIONING',), 'model_name': (folder_paths.get_filename_list('upscale_models'),), 'seed': ('INT', {'default': 0, 'min': 0, 'max': 18446744073709551615}), 'upscale_by': ('FLOAT', {'default': 1.0, 'min': 0.0, 'max': 10.0, 'step': 0.1}), 'hires_strength': ('FLOAT', {'default': 1.0, 'min': 0.0, 'max': 2.0, 'step': 0.1})}}
    RETURN_TYPES = ('LATENT',)
    FUNCTION = 'run'
    CATEGORY = 'Mikey/Sampling'

    def adjust_start_step(self, image_complexity, hires_strength=1.0):
        image_complexity /= 24
        if image_complexity > 1:
            image_complexity = 1
        image_complexity = min([0.55, image_complexity]) * hires_strength
        return min([16, 16 - int(round(image_complexity * 16, 0))])

    def run(self, seed, base_model, refiner_model, vae, samples, positive_cond_base, negative_cond_base, positive_cond_refiner, negative_cond_refiner, model_name, upscale_by=1.0, hires_strength=1.0, upscale_method='normal'):
        image_scaler = ImageScale()
        vaeencoder = VAEEncode()
        vaedecoder = VAEDecode()
        uml = UpscaleModelLoader()
        upscale_model = uml.load_model(model_name)[0]
        iuwm = ImageUpscaleWithModel()
        sample1 = common_ksampler(base_model, seed, 25, 6.5, 'dpmpp_2s_ancestral', 'simple', positive_cond_base, negative_cond_base, samples, start_step=0, last_step=18, force_full_denoise=False)[0]
        sample2 = common_ksampler(refiner_model, seed, 30, 3.5, 'dpmpp_2m', 'simple', positive_cond_refiner, negative_cond_refiner, sample1, disable_noise=True, start_step=21, force_full_denoise=True)
        if upscale_by == 0:
            return sample2
        else:
            sample2 = sample2[0]
        pixels = vaedecoder.decode(vae, sample2)[0]
        (org_width, org_height) = (pixels.shape[2], pixels.shape[1])
        img = iuwm.upscale(upscale_model, image=pixels)[0]
        (upscaled_width, upscaled_height) = (int(org_width * upscale_by // 8 * 8), int(org_height * upscale_by // 8 * 8))
        img = image_scaler.upscale(img, 'nearest-exact', upscaled_width, upscaled_height, 'center')[0]
        if hires_strength == 0:
            return (vaeencoder.encode(vae, img)[0],)
        image_complexity = calculate_image_complexity(img)
        start_step = self.adjust_start_step(image_complexity, hires_strength)
        latent = vaeencoder.encode(vae, img)[0]
        out = common_ksampler(base_model, seed, 16, 9.5, 'dpmpp_2m_sde', 'karras', positive_cond_base, negative_cond_base, latent, start_step=start_step, force_full_denoise=True)
        return out
```