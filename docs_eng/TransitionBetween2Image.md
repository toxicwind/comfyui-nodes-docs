# Documentation
- Class name: TransitionBetween2Image
- Category: AIGC
- Output node: False
- Repo Ref: https://github.com/esheep/esheep_custom_nodes.git

The TranspositionBetween2Image node is used to create a smooth transition between two images. It uses the Bézier curve to insert values, generating a series of frames that transform one image into another. This node is particularly suitable for visual effects that require gradual change from one state to another, such as animation or video processing.

# Input types
## Required
- image_start
    - The initial image that you want to transition to. It sets the initial visual status for the animation sequence.
    - Comfy dtype: IMAGE
    - Python dtype: PIL.Image.Image or numpy.ndarray
- image_end
    - The transition will transform into an end image. It represents the final visual state of the sequence.
    - Comfy dtype: IMAGE
    - Python dtype: PIL.Image.Image or numpy.ndarray
- total_frames
    - The total number of frames to be generated for the transition. An increase in this number would make the transition smoother, but would require more processing time.
    - Comfy dtype: INT
    - Python dtype: int
- begin_and_end_frames
    - Number of frames reproduced at the beginning and end of the transition to provide a pause effect.
    - Comfy dtype: INT
    - Python dtype: int
- beiser_point_x
    - Defines the x-coordinate of the control point on the Bézier curve in the transition shape.
    - Comfy dtype: FLOAT
    - Python dtype: float
- beiser_point_y
    - Defines the y-coordinate of the control point on the Bézier curve in the transition shape.
    - Comfy dtype: FLOAT
    - Python dtype: float

# Output types
- IMAGE
    - Frame sequences generated by transition can be used for further processing or display.
    - Comfy dtype: IMAGE
    - Python dtype: torch.Tensor

# Usage tips
- Infra type: CPU

# Source code
```
class TransitionBetween2Image:

    @classmethod
    def INPUT_TYPES(s):
        return {'required': {'image_start': ('IMAGE',), 'image_end': ('IMAGE',), 'total_frames': ('INT', {'default': 40, 'min': 1}), 'begin_and_end_frames': ('INT', {'default': 10, 'min': 0}), 'beiser_point_x': ('FLOAT', {'default': 0.5, 'min': 0.0, 'max': 1.0, 'step': 0.05}), 'beiser_point_y': ('FLOAT', {'default': 0.5, 'min': 0.0, 'max': 1.0, 'step': 0.05})}}
    RETURN_TYPES = ('IMAGE',)
    FUNCTION = 'get_transition_frames'
    CATEGORY = 'AIGC'

    def get_transition_frames(self, image_start, image_end, total_frames, begin_and_end_frames, beiser_point_x, beiser_point_y):
        origin_image = image_start[0]
        outpating_image = image_end[0]
        frames = []
        origin_width = origin_image.shape[1]
        origin_height = origin_image.shape[0]
        new_width = outpating_image.shape[1]
        new_height = outpating_image.shape[0]
        if new_height / new_width > origin_height / origin_width:
            origin_height = new_height / new_width * origin_width
        else:
            origin_width = new_width / new_height * origin_height
        print(f'image rect = {origin_width} {origin_height} {new_width} {new_height}')
        white_origin_left = int((new_width - origin_width) / 2)
        white_origin_top = int((new_height - origin_height) / 2)
        a = np.array([[0.0, beiser_point_x, 1.0], [0.0, beiser_point_y, 1.0]])
        curve = bezier.Curve(a, degree=2)
        s_vals = np.linspace(0.0, 1.0, total_frames)
        data = curve.evaluate_multi(s_vals)
        print(f' curve data = {data}')
        for a in range(total_frames):
            i = data[1][a]
            current_left = int(white_origin_left * (1 - i))
            current_top = int(white_origin_top * (1 - i))
            current_width = int(origin_width + white_origin_left * i * 2)
            current_height = int(origin_height + white_origin_top * i * 2)
            print(f'a = {a} i = {i}  current rect = {current_left} {current_top} {current_width} {current_height}')
            current_img = outpating_image[current_top:current_top + current_height, current_left:current_left + current_width]
            current_img = current_img.numpy().astype(np.float32)
            img = cv2.resize(current_img, (new_width, new_height))
            frames.append(img)
            if a == 0:
                for j in range(begin_and_end_frames):
                    frames.append(img)
            elif a == total_frames - 1:
                for j in range(begin_and_end_frames):
                    frames.append(img)
        return_array = torch.Tensor(np.asarray(frames))
        return (return_array,)
```