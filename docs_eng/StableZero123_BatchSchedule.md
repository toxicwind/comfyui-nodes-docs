# Documentation
- Class name: StableZero123_BatchSchedule
- Category: KJNodes/experimental
- Output node: False
- Repo Ref: https://github.com/kijai/ComfyUI-KJNodes.git

The StableZero123_BatchSchedule class method handles images and generates potential expressions. It accepts additional settings such as visual model output, initial images, VAE models, and width, height, and volume size. It also uses angle plugs based on the azimuth angles and heights provided, applying different buffer functions for smooth transition. The final output includes positive and negative data and potential image expressions.

# Input types
## Required
- clip_vision
    - The parameter `clip_vision'is essential to encode the initial image as an embedded feature that can be used for further processing. It represents the output from the CLIP visual model and is an essential part of the image processing flow line.
    - Comfy dtype: CLIP_VISION
    - Python dtype: torch.Tensor
- init_image
    - The parameter `init_image'is the original image that needs to be processed. It is the starting point for the potential expression and the necessary input for the node operation.
    - Comfy dtype: IMAGE
    - Python dtype: PIL.Image.Image
- vae
    - Parameters `vae'is a VAE model that is used to encode images into potential space. It plays a key role in converting image data into downstream tasks.
    - Comfy dtype: VAE
    - Python dtype: torch.nn.Module
## Optional
- width
    - Parameters `width'specify the desired width of the post-processing image. It is an important factor in determining the final image resolution and is used in conjunction with the height parameters.
    - Comfy dtype: INT
    - Python dtype: int
- height
    - The parameter `height'defines the size of the processed image with the width parameter. It is the key setting that controls the size of the output image.
    - Comfy dtype: INT
    - Python dtype: int
- batch_size
    - The parameter `batch_size'determines the number of images to be processed at a time. It is an important consideration for optimizing node performance and memory use.
    - Comfy dtype: INT
    - Python dtype: int
- interpolation
    - Parameter `interpolation'allows the selection of different plug-in methods for adjusting the image over a period of time. It affects the smoothness and appearance of the final image.
    - Comfy dtype: COMBO[linear, ease_in, ease_out, ease_in_out]
    - Python dtype: str
- azimuth_points_string
    - The parameter `azimuth_points_string'contains a string representation of the azimuth that is used for angle plug-in values. It is essential in defining the angular transition in image processing.
    - Comfy dtype: STRING
    - Python dtype: str
- elevation_points_string
    - Parameters `elevation_points_string'specify a height point in the form of a string to control the vertical angle transition during image processing.
    - Comfy dtype: STRING
    - Python dtype: str

# Output types
- positive
    - Output `positive'contains positive condition data derived from image processing. It is used to guide the generation of images similar to the input image.
    - Comfy dtype: CONDITIONING
    - Python dtype: List[Tuple[torch.Tensor, Dict[str, torch.Tensor]]]
- negative
    - Output `negative'provides negative condition data to guide the generation of images that are different from the input image.
    - Comfy dtype: CONDITIONING
    - Python dtype: List[Tuple[torch.Tensor, Dict[str, torch.Tensor]]]
- latent
    - Output `latet'means a sample of potential images generated by nodes. These samples are low-dimensional expressions of input images and apply to various image generation tasks.
    - Comfy dtype: LATENT
    - Python dtype: Dict[str, torch.Tensor]

# Usage tips
- Infra type: GPU

# Source code
```
class StableZero123_BatchSchedule:

    @classmethod
    def INPUT_TYPES(s):
        return {'required': {'clip_vision': ('CLIP_VISION',), 'init_image': ('IMAGE',), 'vae': ('VAE',), 'width': ('INT', {'default': 256, 'min': 16, 'max': MAX_RESOLUTION, 'step': 8}), 'height': ('INT', {'default': 256, 'min': 16, 'max': MAX_RESOLUTION, 'step': 8}), 'batch_size': ('INT', {'default': 1, 'min': 1, 'max': 4096}), 'interpolation': (['linear', 'ease_in', 'ease_out', 'ease_in_out'],), 'azimuth_points_string': ('STRING', {'default': '0:(0.0),\n7:(1.0),\n15:(0.0)\n', 'multiline': True}), 'elevation_points_string': ('STRING', {'default': '0:(0.0),\n7:(0.0),\n15:(0.0)\n', 'multiline': True})}}
    RETURN_TYPES = ('CONDITIONING', 'CONDITIONING', 'LATENT')
    RETURN_NAMES = ('positive', 'negative', 'latent')
    FUNCTION = 'encode'
    CATEGORY = 'KJNodes/experimental'

    def encode(self, clip_vision, init_image, vae, width, height, batch_size, azimuth_points_string, elevation_points_string, interpolation):
        output = clip_vision.encode_image(init_image)
        pooled = output.image_embeds.unsqueeze(0)
        pixels = comfy.utils.common_upscale(init_image.movedim(-1, 1), width, height, 'bilinear', 'center').movedim(1, -1)
        encode_pixels = pixels[:, :, :, :3]
        t = vae.encode(encode_pixels)

        def ease_in(t):
            return t * t

        def ease_out(t):
            return 1 - (1 - t) * (1 - t)

        def ease_in_out(t):
            return 3 * t * t - 2 * t * t * t
        azimuth_points = []
        azimuth_points_string = azimuth_points_string.rstrip(',\n')
        for point_str in azimuth_points_string.split(','):
            (frame_str, azimuth_str) = point_str.split(':')
            frame = int(frame_str.strip())
            azimuth = float(azimuth_str.strip()[1:-1])
            azimuth_points.append((frame, azimuth))
        azimuth_points.sort(key=lambda x: x[0])
        elevation_points = []
        elevation_points_string = elevation_points_string.rstrip(',\n')
        for point_str in elevation_points_string.split(','):
            (frame_str, elevation_str) = point_str.split(':')
            frame = int(frame_str.strip())
            elevation_val = float(elevation_str.strip()[1:-1])
            elevation_points.append((frame, elevation_val))
        elevation_points.sort(key=lambda x: x[0])
        next_point = 1
        next_elevation_point = 1
        positive_cond_out = []
        positive_pooled_out = []
        negative_cond_out = []
        negative_pooled_out = []
        for i in range(batch_size):
            while next_point < len(azimuth_points) and i >= azimuth_points[next_point][0]:
                next_point += 1
            if next_point == len(azimuth_points):
                next_point -= 1
            prev_point = max(next_point - 1, 0)
            if azimuth_points[next_point][0] != azimuth_points[prev_point][0]:
                fraction = (i - azimuth_points[prev_point][0]) / (azimuth_points[next_point][0] - azimuth_points[prev_point][0])
                if interpolation == 'ease_in':
                    fraction = ease_in(fraction)
                elif interpolation == 'ease_out':
                    fraction = ease_out(fraction)
                elif interpolation == 'ease_in_out':
                    fraction = ease_in_out(fraction)
                interpolated_azimuth = interpolate_angle(azimuth_points[prev_point][1], azimuth_points[next_point][1], fraction)
            else:
                interpolated_azimuth = azimuth_points[prev_point][1]
            next_elevation_point = 1
            while next_elevation_point < len(elevation_points) and i >= elevation_points[next_elevation_point][0]:
                next_elevation_point += 1
            if next_elevation_point == len(elevation_points):
                next_elevation_point -= 1
            prev_elevation_point = max(next_elevation_point - 1, 0)
            if elevation_points[next_elevation_point][0] != elevation_points[prev_elevation_point][0]:
                fraction = (i - elevation_points[prev_elevation_point][0]) / (elevation_points[next_elevation_point][0] - elevation_points[prev_elevation_point][0])
                if interpolation == 'ease_in':
                    fraction = ease_in(fraction)
                elif interpolation == 'ease_out':
                    fraction = ease_out(fraction)
                elif interpolation == 'ease_in_out':
                    fraction = ease_in_out(fraction)
                interpolated_elevation = interpolate_angle(elevation_points[prev_elevation_point][1], elevation_points[next_elevation_point][1], fraction)
            else:
                interpolated_elevation = elevation_points[prev_elevation_point][1]
            cam_embeds = camera_embeddings(interpolated_elevation, interpolated_azimuth)
            cond = torch.cat([pooled, cam_embeds.repeat((pooled.shape[0], 1, 1))], dim=-1)
            positive_pooled_out.append(t)
            positive_cond_out.append(cond)
            negative_pooled_out.append(torch.zeros_like(t))
            negative_cond_out.append(torch.zeros_like(pooled))
        final_positive_cond = torch.cat(positive_cond_out, dim=0)
        final_positive_pooled = torch.cat(positive_pooled_out, dim=0)
        final_negative_cond = torch.cat(negative_cond_out, dim=0)
        final_negative_pooled = torch.cat(negative_pooled_out, dim=0)
        final_positive = [[final_positive_cond, {'concat_latent_image': final_positive_pooled}]]
        final_negative = [[final_negative_cond, {'concat_latent_image': final_negative_pooled}]]
        latent = torch.zeros([batch_size, 4, height // 8, width // 8])
        return (final_positive, final_negative, {'samples': latent})
```