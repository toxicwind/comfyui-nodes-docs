# Documentation
- Class name: SepconvVFI
- Category: ComfyUI-Frame-Interpolation/VFI
- Output node: False
- Repo Ref: https://github.com/Fannovel16/ComfyUI-Frame-Interpolation

The SepconvVFI node is designed to execute video frame plugs using a severable volume neural network. It enhances the fluidity and smoothness of the transition between frames in the video sequence and helps to provide a higher-quality visual experience without requiring significant costing.

# Input types
## Required
- ckpt_name
    - The name of the check point is essential for loading pre-training model weights that are necessary for the frame plug-in process. It ensures that the model generates accurate and high-quality plug-in frames.
    - Comfy dtype: str
    - Python dtype: str
- frames
    - The input frame is the original video data that the node handles to create the middle frame. This input is essential because it forms the basis for the plug-in task.
    - Comfy dtype: IMAGE
    - Python dtype: torch.Tensor
## Optional
- clear_cache_after_n_frames
    - This parameter determines how often a GPU cache is cleared during the process to maintain optimal performance. This is an optional setting that can help manage management system resources.
    - Comfy dtype: INT
    - Python dtype: int
- multiplier
    - Multiplier affects the number of plug-ins between two input frames. It is an optional parameter that allows users to control the density of the plug-in frames.
    - Comfy dtype: INT
    - Python dtype: int
- optional_interpolation_states
    - This optional parameter provides additional control over the plug-in process and allows for the customization of the plug-in state for each frame.
    - Comfy dtype: INTERPOLATION_STATES
    - Python dtype: InterpolationStateList

# Output types
- output_frames
    - The output_frames parameters contain the plug-in frames generated by nodes. These frames are the result of the frame-plug-in process and are important for creating a smoother video transition.
    - Comfy dtype: IMAGE
    - Python dtype: torch.Tensor

# Usage tips
- Infra type: GPU

# Source code
```
class SepconvVFI:

    @classmethod
    def INPUT_TYPES(s):
        return {'required': {'ckpt_name': (CKPT_NAMES,), 'frames': ('IMAGE',), 'clear_cache_after_n_frames': ('INT', {'default': 10, 'min': 1, 'max': 1000}), 'multiplier': ('INT', {'default': 2, 'min': 2, 'max': 1000})}, 'optional': {'optional_interpolation_states': ('INTERPOLATION_STATES',)}}
    RETURN_TYPES = ('IMAGE',)
    FUNCTION = 'vfi'
    CATEGORY = 'ComfyUI-Frame-Interpolation/VFI'

    def vfi(self, ckpt_name: typing.AnyStr, frames: torch.Tensor, clear_cache_after_n_frames=10, multiplier: typing.SupportsInt=2, optional_interpolation_states: InterpolationStateList=None, **kwargs):
        from .sepconv_enhanced import Network
        model_path = load_file_from_github_release(MODEL_TYPE, ckpt_name)
        interpolation_model = Network()
        interpolation_model.load_state_dict(torch.load(model_path))
        interpolation_model.eval().to(get_torch_device())
        frames = preprocess_frames(frames)

        def return_middle_frame(frame_0, frame_1, timestep, model):
            return model(frame_0, frame_1)
        args = [interpolation_model]
        out = postprocess_frames(generic_frame_loop(frames, clear_cache_after_n_frames, multiplier, return_middle_frame, *args, interpolation_states=optional_interpolation_states, use_timestep=False, dtype=torch.float32))
        return (out,)
```