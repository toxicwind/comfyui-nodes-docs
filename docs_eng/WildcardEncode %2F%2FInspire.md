# Documentation
- Class name: WildcardEncodeInspire
- Category: InspirePack/Prompt
- Output node: False
- Repo Ref: https://github.com/ltdrdata/ComfyUI-Inspire-Pack.git

The Wildcard Encode Inspire node is designed to process and encode text input with wildcards and Lora (low-end adaptation) blocks, integrating them into models and clip conditions to stabilize diffusion. It enhances the creativity and adaptability of the output content by creating tips based on user input or fixed text dynamics. This node is essential for users seeking to use advanced text coding techniques to improve the quality and relevance of the content generated by AI.

# Input types
## Required
- model
    - Model parameters are essential because they define the basic AI models that will be used for text coding and processing. They directly affect the quality and characteristics of the content generated, ensuring that the output is consistent with the capabilities and training data of the specified model.
    - Comfy dtype: MODEL
    - Python dtype: torch.nn.Module
- clip
    - The clip parameter is essential for integrating text with visual context, enabling nodes to generate not only text-coherent but visually relevant tips. It plays an important role in ensuring that AI output is consistent with the desired visual element.
    - Comfy dtype: CLIP
    - Python dtype: CLIPModel
- token_normalization
    - The token_normalization parameter is important for pre-processing text tags before encoding. It standardizes tag values, which improves the efficiency and accuracy of the text coding process and ensures that the AI model better understands and processes input text.
    - Comfy dtype: COMBO
    - Python dtype: str
- weight_interpretation
    - Weight_interpretation parameters play a key role in determining how nodes interpret and apply weights in the encoding process. They influence the emphasis on different parts of the text, which can significantly influence the focus and detail of the final output.
    - Comfy dtype: COMBO
    - Python dtype: str
- wildcard_text
    - The wildcard_text parameter is the core of the node function because it contains templates with wildcards that will be filled or replaced during the encoding process. It is the basis for generating dynamic and adaptable tips.
    - Comfy dtype: STRING
    - Python dtype: str
- populated_text
    - The populated_text parameter saves the final text after processing wildcards for actual encoding and the generation of AI content. It is the result of the main function of the node, which directly influences the output.
    - Comfy dtype: STRING
    - Python dtype: str
- mode
    - Mode parameters control whether the node generates dynamic tips (populate) or uses fixed text (Fixed) based on user input. This setting is essential to determine the flexibility and adaptability to generate the tips.
    - Comfy dtype: BOOLEAN
    - Python dtype: bool
- seed
    - The Seed parameter is used to introduce randomity in the encoding process, allowing for diverse and unique output. It ensures that even when you enter the same, it produces different results, increasing the variability of AI output.
    - Comfy dtype: INT
    - Python dtype: int
## Optional
- Select to add LoRA
    - 'Select to add the LoRA' parameter to allow the user to add a specific LoRA block to the text and to enhance the encoding process through additional context information. This significantly enhances the relevance and depth of the AI-generated content.
    - Comfy dtype: COMBO
    - Python dtype: str
- Select to add Wildcard
    - This parameter allows the user to add specific wildcards to the text that can be dynamically filled or replaced during the encoding process. This is a key aspect of the custom output to meet specific creative or thematic requirements.
    - Comfy dtype: COMBO
    - Python dtype: str

# Output types
- model
    - Model output is an updated AI model with coded text and conditions to generate content based on input and processing parameters. It represents the result of node coding.
    - Comfy dtype: MODEL
    - Python dtype: torch.nn.Module
- clip
    - The clip output integrates the visual context of the input and enhances the ability of AI to generate not only text-coherent content but also visually aligned content with that provided.
    - Comfy dtype: CLIP
    - Python dtype: CLIPModel
- conditioning
    - Conditional output provides additional context and guidance for the AI model to ensure that the content generated meets the specified theme and requirements. It is a key component for achieving targeted and relevant AI output.
    - Comfy dtype: CONDITIONING
    - Python dtype: Dict[str, torch.Tensor]
- populated_text
    - Populated_text output is the final processed text, with wildcards filled or replaced for use in the generation of the AI model. It is the direct result of node coding and processing activities.
    - Comfy dtype: STRING
    - Python dtype: str

# Usage tips
- Infra type: GPU

# Source code
```
class WildcardEncodeInspire:

    @classmethod
    def INPUT_TYPES(s):
        return {'required': {'model': ('MODEL',), 'clip': ('CLIP',), 'token_normalization': (['none', 'mean', 'length', 'length+mean'],), 'weight_interpretation': (['comfy', 'A1111', 'compel', 'comfy++', 'down_weight'], {'default': 'comfy++'}), 'wildcard_text': ('STRING', {'multiline': True, 'dynamicPrompts': False, 'placeholder': 'Wildcard Prompt (User Input)'}), 'populated_text': ('STRING', {'multiline': True, 'dynamicPrompts': False, 'placeholder': 'Populated Prompt (Will be generated automatically)'}), 'mode': ('BOOLEAN', {'default': True, 'label_on': 'Populate', 'label_off': 'Fixed'}), 'Select to add LoRA': (['Select the LoRA to add to the text'] + folder_paths.get_filename_list('loras'),), 'Select to add Wildcard': (['Select the Wildcard to add to the text'],), 'seed': ('INT', {'default': 0, 'min': 0, 'max': 18446744073709551615})}}
    CATEGORY = 'InspirePack/Prompt'
    RETURN_TYPES = ('MODEL', 'CLIP', 'CONDITIONING', 'STRING')
    RETURN_NAMES = ('model', 'clip', 'conditioning', 'populated_text')
    FUNCTION = 'doit'

    def doit(self, *args, **kwargs):
        populated = kwargs['populated_text']
        clip_encoder = BNK_EncoderWrapper(kwargs['token_normalization'], kwargs['weight_interpretation'])
        if 'ImpactWildcardEncode' not in nodes.NODE_CLASS_MAPPINGS:
            utils.try_install_custom_node('https://github.com/ltdrdata/ComfyUI-Impact-Pack', "To use 'Wildcard Encode (Inspire)' node, 'Impact Pack' extension is required.")
            raise Exception(f"[ERROR] To use 'Wildcard Encode (Inspire)', you need to install 'Impact Pack'")
        (model, clip, conditioning) = nodes.NODE_CLASS_MAPPINGS['ImpactWildcardEncode'].process_with_loras(wildcard_opt=populated, model=kwargs['model'], clip=kwargs['clip'], clip_encoder=clip_encoder)
        return (model, clip, conditioning, populated)
```