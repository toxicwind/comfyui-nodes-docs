# Documentation
- Class name: SimpleDetectorForEachPipe
- Category: ImpactPack/Detector
- Output node: False
- Repo Ref: https://github.com/ltdrdata/ComfyUI-Impact-Pack.git

The SimpleDectorForEachPipe node is designed to process images through predefined detection pipes. It takes into account the parameters of various impact detection processes, such as boundary frame thresholds and inflation, to improve the accuracy of the tests. The function of the node is to identify and locate objects in the image, contributing to the broader objective of image analysis and object identification.

# Input types
## Required
- detailer_pipe
    - The detailer_pipe parameter is essential to the operation of the node because it defines a series of operations or pipelines that should be used to enter images for testing. It is a key component that determines the behaviour of the node and the quality of the test results.
    - Comfy dtype: DETAILER_PIPE
    - Python dtype: Tuple[Any, ...]
- image
    - The image parameter is the main input of the node, which represents the data to be processed for the target test. The importance of the node is that it is the object of the test operation, and the performance and results of the node are directly dependent on the quality and properties of the input image.
    - Comfy dtype: IMAGE
    - Python dtype: torch.Tensor
- bbox_threshold
    - The bbox_threshold parameter determines the level of confidence that the boundary box is considered to be effective for detection. It plays an important role in filtering errors and ensuring that only high-confidence tests are included in the output.
    - Comfy dtype: FLOAT
    - Python dtype: float
- bbox_dilation
    - The bbox_dilation parameter controls the inflation applied to the boundary box, which helps to adjust the size of the detected object. This parameter is important for fine-tuning the accuracy of the detection to better meet the specific requirements of the application.
    - Comfy dtype: INT
    - Python dtype: int
- crop_factor
    - The crop_factor parameter is used to determine the image parts that are to be considered for testing. It is important because it helps to concentrate the detection process in the most relevant areas of the image, which may improve the efficiency and accuracy of node operations.
    - Comfy dtype: FLOAT
    - Python dtype: float
- drop_size
    - The drop_size parameter specifies the size of the cell of the grid that divides the image for the purpose of detection. It affects the particle size of the detection and is essential for determining the level of detail of the test results.
    - Comfy dtype: INT
    - Python dtype: int
- sub_threshold
    - Sub_threshold parameters set thresholds for secondary testing that can be used to fine-tune the detection process by focusing on smaller or less prominent objects in the image.
    - Comfy dtype: FLOAT
    - Python dtype: float
- sub_dilation
    - The sub_dilation parameter allows the application of inflation to adjust the size of the secondary test. It is important for controlling the size of the detected object and can be used to optimize the detection for specific scenarios.
    - Comfy dtype: INT
    - Python dtype: int
- sub_bbox_expansion
    - Sub_bbox_expansion parameters control the extension of the boundary box for secondary testing. It is important because it helps capture the wider context around smaller objects, which may improve the accuracy of the tests.
    - Comfy dtype: INT
    - Python dtype: int
- sam_mask_hint_threshold
    - The sam_mask_hint_threshold parameter is used to define the threshold for mask hints generated by the SAM model. It is important to control the level of detail in the partition mask and can influence the final detection results.
    - Comfy dtype: FLOAT
    - Python dtype: float
## Optional
- post_dilation
    - Post_dilation parameters provide an additional control layer for the final boundary frame by allowing inflation after the main testing process. It can be used to fine-tune the results for specific cases.
    - Comfy dtype: INT
    - Python dtype: Optional[int]

# Output types
- segs
    - The segs output parameter represents the partition area detected in the input image. It is important because it contains the main results of the testing process and provides valuable insights into the composition and structure of the image.
    - Comfy dtype: SEGS
    - Python dtype: Tuple[torch.Tensor, ...]

# Usage tips
- Infra type: GPU

# Source code
```
class SimpleDetectorForEachPipe:

    @classmethod
    def INPUT_TYPES(s):
        return {'required': {'detailer_pipe': ('DETAILER_PIPE',), 'image': ('IMAGE',), 'bbox_threshold': ('FLOAT', {'default': 0.5, 'min': 0.0, 'max': 1.0, 'step': 0.01}), 'bbox_dilation': ('INT', {'default': 0, 'min': -512, 'max': 512, 'step': 1}), 'crop_factor': ('FLOAT', {'default': 3.0, 'min': 1.0, 'max': 100, 'step': 0.1}), 'drop_size': ('INT', {'min': 1, 'max': MAX_RESOLUTION, 'step': 1, 'default': 10}), 'sub_threshold': ('FLOAT', {'default': 0.5, 'min': 0.0, 'max': 1.0, 'step': 0.01}), 'sub_dilation': ('INT', {'default': 0, 'min': -512, 'max': 512, 'step': 1}), 'sub_bbox_expansion': ('INT', {'default': 0, 'min': 0, 'max': 1000, 'step': 1}), 'sam_mask_hint_threshold': ('FLOAT', {'default': 0.7, 'min': 0.0, 'max': 1.0, 'step': 0.01})}, 'optional': {'post_dilation': ('INT', {'default': 0, 'min': -512, 'max': 512, 'step': 1})}}
    RETURN_TYPES = ('SEGS',)
    FUNCTION = 'doit'
    CATEGORY = 'ImpactPack/Detector'

    def doit(self, detailer_pipe, image, bbox_threshold, bbox_dilation, crop_factor, drop_size, sub_threshold, sub_dilation, sub_bbox_expansion, sam_mask_hint_threshold, post_dilation=0):
        if len(image) > 1:
            raise Exception('[Impact Pack] ERROR: SimpleDetectorForEach does not allow image batches.\nPlease refer to https://github.com/ltdrdata/ComfyUI-extension-tutorials/blob/Main/ComfyUI-Impact-Pack/tutorial/batching-detailer.md for more information.')
        (model, clip, vae, positive, negative, wildcard, bbox_detector, segm_detector_opt, sam_model_opt, detailer_hook, refiner_model, refiner_clip, refiner_positive, refiner_negative) = detailer_pipe
        return SimpleDetectorForEach.detect(bbox_detector, image, bbox_threshold, bbox_dilation, crop_factor, drop_size, sub_threshold, sub_dilation, sub_bbox_expansion, sam_mask_hint_threshold, post_dilation=post_dilation, sam_model_opt=sam_model_opt, segm_detector_opt=segm_detector_opt, detailer_hook=detailer_hook)
```