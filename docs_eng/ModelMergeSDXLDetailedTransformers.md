# Documentation
- Class name: ModelMergeSDXLDetailedTransformers
- Category: model_merging
- Output node: False
- Repo Ref: https://github.com/comfyanonymous/ComfyUI_experiments

The Model Merge SDXLDetailed Transformers node is designed to integrate multiple models into a single, unified structure. It creates an enhanced model with improved performance by combining different model components, such as embedded layers and transformers. The node emphasizes seamless integration of models to take advantage of their combined advantages.

# Input types
## Required
- model1
    - The parameter'model1' is essential because it represents the first model to be merged within a node. Its integration with other models is essential to consolidate the overall function and performance of the model.
    - Comfy dtype: MODEL
    - Python dtype: torch.nn.Module
- model2
    - The parameter'model2' is another key component of the consolidation process, representing the second model to be combined. It is important to achieve the desired capability of the eventual merger model.
    - Comfy dtype: MODEL
    - Python dtype: torch.nn.Module
## Optional
- time_embed.
    - The parameter 'time_embed.' allows time-based embedding into models, which may be important for time-sensitive tasks of data.
    - Comfy dtype: FLOAT
    - Python dtype: float
- input_blocks
    - The parameter 'input_blocks' is a complex structure with multiple sub-parameters, each of which represents different transformer blocks in the model input section. These blocks play a key role in processing input data and are configured according to the needs of the model.
    - Comfy dtype: COMBO[FLOAT]
    - Python dtype: Dict[str, Union[float, torch.Tensor]]
- middle_block
    - The parameter'middle_block' refers to the intermediate part of the model, where additional layers or operations can be applied. It plays a vital role in the ability of the model to process and convert data and then transmit them to the output layer.
    - Comfy dtype: COMBO[FLOAT]
    - Python dtype: Dict[str, Union[float, torch.Tensor]]
- output_blocks
    - The parameter 'output_blocks' defines the output part of the model and consists of a variety of variable blocks that generate final predictions or outputs based on processed data.
    - Comfy dtype: COMBO[FLOAT]
    - Python dtype: Dict[str, Union[float, torch.Tensor]]
- out.
    - The parameter 'out.'is the final output of the merged model, which contains the results of all processing steps completed.
    - Comfy dtype: FLOAT
    - Python dtype: float

# Output types
- merged_model
    - Output'merged_model' represents the final integrated model generated by the consolidation process. It contains the combined capacity to enter the model and improves the overall performance of the downstream task.
    - Comfy dtype: MODEL
    - Python dtype: torch.nn.Module

# Usage tips
- Infra type: GPU

# Source code
```
class ModelMergeSDXLDetailedTransformers(comfy_extras.nodes_model_merging.ModelMergeBlocks):

    @classmethod
    def INPUT_TYPES(s):
        arg_dict = {'model1': ('MODEL',), 'model2': ('MODEL',)}
        argument = ('FLOAT', {'default': 1.0, 'min': 0.0, 'max': 1.0, 'step': 0.01})
        arg_dict['time_embed.'] = argument
        arg_dict['label_emb.'] = argument
        transformers = {4: 2, 5: 2, 7: 10, 8: 10}
        transformers_args = ['norm1', 'attn1.to_q', 'attn1.to_k', 'attn1.to_v', 'attn1.to_out', 'ff.net', 'norm2', 'attn2.to_q', 'attn2.to_k', 'attn2.to_v', 'attn2.to_out', 'norm3']
        for i in range(9):
            arg_dict['input_blocks.{}.0.'.format(i)] = argument
            if i in transformers:
                arg_dict['input_blocks.{}.1.'.format(i)] = argument
                for j in range(transformers[i]):
                    for x in transformers_args:
                        arg_dict['input_blocks.{}.1.transformer_blocks.{}.{}'.format(i, j, x)] = argument
        for i in range(3):
            arg_dict['middle_block.{}.'.format(i)] = argument
            if i == 1:
                for j in range(10):
                    for x in transformers_args:
                        arg_dict['middle_block.{}.transformer_blocks.{}.{}'.format(i, j, x)] = argument
        transformers = {3: 2, 4: 2, 5: 2, 6: 10, 7: 10, 8: 10}
        for i in range(9):
            arg_dict['output_blocks.{}.0.'.format(i)] = argument
            t = 8 - i
            if t in transformers:
                arg_dict['output_blocks.{}.1.'.format(i)] = argument
                for j in range(transformers[t]):
                    for x in transformers_args:
                        arg_dict['output_blocks.{}.1.transformer_blocks.{}.{}'.format(i, j, x)] = argument
        arg_dict['out.'] = argument
        return {'required': arg_dict}
```