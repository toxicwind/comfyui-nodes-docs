# Documentation
- Class name: StableZero123_Conditioning_Batched
- Category: conditioning/3d_models
- Output node: False
- Repo Ref: https://github.com/comfyanonymous/ComfyUI

The node aims at bulk processing and generation of 3D model reconciliation data, integrating visual and spatial information to enhance model performance.

# Input types
## Required
- clip_vision
    - Clip_vision parameters are essential for encoding visual information from images, which is essential for nodes to produce accurate and meaningful reconciliation data.
    - Comfy dtype: CLIP_VISION
    - Python dtype: comfy.model_patcher.ModelPatcher
- init_image
    - The init_image parameter is the basis for node operations and provides the initial visual context, which is magnified and coded for further processing.
    - Comfy dtype: IMAGE
    - Python dtype: PIL.Image.Image
- vae
    - The vae parameter is essential to encode visual data into potential space, enabling nodes to effectively generate the reconciliation data used to manipulate the 3D model.
    - Comfy dtype: VAE
    - Python dtype: torch.nn.Module
- width
    - The width parameter determines the horizontal resolution of the magnified image and affects the level of detail and complexity of the reconciliation data generated by nodes.
    - Comfy dtype: INT
    - Python dtype: int
- height
    - The height parameters set the vertical resolution for magnifying the image, directly affecting the quality and abundance of the 3D model reconciliation data.
    - Comfy dtype: INT
    - Python dtype: int
- batch_size
    - Match_size parameters determine the number of operations that can be carried out simultaneously at nodes, increasing the efficiency and throughput of the 3D model reconciliation process.
    - Comfy dtype: INT
    - Python dtype: int
- elevation
    - Elevation parameters specify the vertical angle of the camera, which is important for creating real and contextually accurate 3D model reconciliation data.
    - Comfy dtype: FLOAT
    - Python dtype: float
- azimuth
    - The azimuth parameter defines the horizontal angle of the camera and influences the perspective and direction of the 3D model reconciliation data.
    - Comfy dtype: FLOAT
    - Python dtype: float
- elevation_batch_increment
    - The parameters allow for batch adjustment of the vertical angle of the camera to ensure diversification of the 3D model reconciliation data.
    - Comfy dtype: FLOAT
    - Python dtype: float
- azimuth_batch_increment
    - The azimuth_batch_increment parameters facilitate batch adjustment of camera horizontal angles and contribute to the diversity of 3D model reconciliation data.
    - Comfy dtype: FLOAT
    - Python dtype: float

# Output types
- positive
    - Positive output provides a set of reconciliation data representing the desired state of the 3D model as guidance for model generation and manipulation.
    - Comfy dtype: CONDITIONING
    - Python dtype: List[Tuple[torch.Tensor, Dict[str, torch.Tensor]]]
- negative
    - Negative output provides a set of additional reconciliation data that defines the undesired state of the 3D model and helps refine and constrain the generation process.
    - Comfy dtype: CONDITIONING
    - Python dtype: List[Tuple[torch.Tensor, Dict[str, torch.Tensor]]]
- latent
    - The potential output contains space and visual information coded and forms the basis for internal expression and manipulation of the 3D model within the system.
    - Comfy dtype: LATENT
    - Python dtype: torch.Tensor

# Usage tips
- Infra type: GPU

# Source code
```
class StableZero123_Conditioning_Batched:

    @classmethod
    def INPUT_TYPES(s):
        return {'required': {'clip_vision': ('CLIP_VISION',), 'init_image': ('IMAGE',), 'vae': ('VAE',), 'width': ('INT', {'default': 256, 'min': 16, 'max': nodes.MAX_RESOLUTION, 'step': 8}), 'height': ('INT', {'default': 256, 'min': 16, 'max': nodes.MAX_RESOLUTION, 'step': 8}), 'batch_size': ('INT', {'default': 1, 'min': 1, 'max': 4096}), 'elevation': ('FLOAT', {'default': 0.0, 'min': -180.0, 'max': 180.0, 'step': 0.1, 'round': False}), 'azimuth': ('FLOAT', {'default': 0.0, 'min': -180.0, 'max': 180.0, 'step': 0.1, 'round': False}), 'elevation_batch_increment': ('FLOAT', {'default': 0.0, 'min': -180.0, 'max': 180.0, 'step': 0.1, 'round': False}), 'azimuth_batch_increment': ('FLOAT', {'default': 0.0, 'min': -180.0, 'max': 180.0, 'step': 0.1, 'round': False})}}
    RETURN_TYPES = ('CONDITIONING', 'CONDITIONING', 'LATENT')
    RETURN_NAMES = ('positive', 'negative', 'latent')
    FUNCTION = 'encode'
    CATEGORY = 'conditioning/3d_models'

    def encode(self, clip_vision, init_image, vae, width, height, batch_size, elevation, azimuth, elevation_batch_increment, azimuth_batch_increment):
        output = clip_vision.encode_image(init_image)
        pooled = output.image_embeds.unsqueeze(0)
        pixels = comfy.utils.common_upscale(init_image.movedim(-1, 1), width, height, 'bilinear', 'center').movedim(1, -1)
        encode_pixels = pixels[:, :, :, :3]
        t = vae.encode(encode_pixels)
        cam_embeds = []
        for i in range(batch_size):
            cam_embeds.append(camera_embeddings(elevation, azimuth))
            elevation += elevation_batch_increment
            azimuth += azimuth_batch_increment
        cam_embeds = torch.cat(cam_embeds, dim=0)
        cond = torch.cat([comfy.utils.repeat_to_batch_size(pooled, batch_size), cam_embeds], dim=-1)
        positive = [[cond, {'concat_latent_image': t}]]
        negative = [[torch.zeros_like(pooled), {'concat_latent_image': torch.zeros_like(t)}]]
        latent = torch.zeros([batch_size, 4, height // 8, width // 8])
        return (positive, negative, {'samples': latent, 'batch_index': [0] * batch_size})
```